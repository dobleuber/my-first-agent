![image](https://github.com/user-attachments/assets/3e1b165e-5465-40ee-871f-64fe623b45b3)


# ğŸ§  Workshop â€“ Crea tu primer AI Agent con LangGraph

Este proyecto es una plantilla diseÃ±ada para enseÃ±ar a desarrolladores cÃ³mo crear agentes conversacionales usando LangGraph. Algunas de sus caracterÃ­sticas clave incluyen:

* Agente ReAct funcional, con razonamiento y herramientas
* Backend basado en LangGraph y LangChain
* Frontend moderno con Next.js 15, Tailwind CSS y Radix UI
* Arquitectura monorepo con Turborepo
* Streaming en tiempo real de respuestas del agente
* Soporte para mÃºltiples modelos LLM como Anthropic Claude y OpenAI GPT
* IntegraciÃ³n con herramientas externas como Tavily
* Interfaz de chat interactiva y personalizable

Este proyecto sirve como base para aprender, prototipar y extender agentes mÃ¡s avanzados.

Este repositorio contiene los pasos y materiales necesarios para completar el workshop de creaciÃ³n de agentes conversacionales con [LangGraph](https://github.com/langchain-ai/langgraph).

AprenderÃ¡s a generar un proyecto desde cero usando [`create-agent-chat-app`](https://github.com/langchain-ai/create-agent-chat-app) y a personalizar un agente ReAct dentro de una app React con Next.js.

---

## ğŸš€ Paso 1 â€“ Genera tu proyecto

Ejecuta el siguiente comando en tu terminal:

```bash
npx create-agent-chat-app
```

Responde a las siguientes opciones cuando se te pregunte:

```
â—‡  What is the name of your project? my-first-agent
â—‡  Which package manager would you like to use? â€º npm
â—‡  Would you like to automatically install dependencies? Y
â—‡  Which framework would you like to use? â€º Next.js
â—†  Which pre-built agents would you like to include?
â”‚  [x] ReAct Agent
â”‚  [ ] Memory Agent
â”‚  [ ] Research Agent
â”‚  [ ] Retrieval Agent
```

Esto crearÃ¡ una nueva carpeta `my-first-agent` con todo el cÃ³digo necesario para empezar.

---

## âš™ï¸ Paso 2 â€“ Configura las variables de entorno

Dentro del directorio del proyecto (`my-first-agent`), copia el archivo de ejemplo de variables de entorno:

```bash
cp .env.example .env
```

> ğŸ“ Este archivo contiene las claves necesarias para ejecutar el agente. AsegÃºrate de reemplazar los valores por tus propias credenciales antes de continuar.

NecesitarÃ¡s obtener claves API desde los siguientes proveedores:

* [Anthropic](https://console.anthropic.com/account/keys)
* [OpenAI](https://platform.openai.com/api-keys)
* [Tavily](https://app.tavily.com/settings/api-keys)
* Gemini, Grok, etc.

> âš™ï¸ El proyecto viene configurado por defecto para funcionar con **Anthropic**. Si deseas usar otro proveedor (como OpenAI), ademÃ¡s de configurar la clave correspondiente en el `.env`, debes modificar el modelo por defecto en el archivo:
>
> ```ts
> apps/agents/src/react-agent/configuration.ts
> ```

---

## ğŸ’» Paso 3 â€“ Ejecuta el proyecto en desarrollo

Dentro del directorio del proyecto:

```bash
npm run dev
```

Luego abre tu navegador en:

```
http://localhost:3000
```

AhÃ­ podrÃ¡s empezar a interactuar con tu primer agente conversacional.

AdemÃ¡s, si estÃ¡s ejecutando el backend correctamente, tambiÃ©n tendrÃ¡s acceso a:

* ğŸš€ API: [http://localhost:2024](http://localhost:2024)
* ğŸ¨ Studio UI: [https://smith.langchain.com/studio?baseUrl=http://localhost:2024](https://smith.langchain.com/studio?baseUrl=http://localhost:2024) â€“ esta herramienta permite interactuar y depurar el comportamiento del agente en tiempo real

---

## ğŸ“ Paso 4 â€“ Â¿Y ahora quÃ©?

En esta etapa vamos a interactuar directamente con el agente.

Puedes hacer lo siguiente:

* Utiliza la ventana de chat en `http://localhost:3000` para probar prompts y ver cÃ³mo responde el agente.
* Abre la interfaz de LangSmith Studio ([https://smith.langchain.com/studio?baseUrl=http://localhost:2024](https://smith.langchain.com/studio?baseUrl=http://localhost:2024)) para observar cÃ³mo se ejecutan los pasos del grafo en tiempo real, ver trazas y depurar su comportamiento.

---

## ğŸ§© Paso 5 â€“ DescripciÃ³n del proyecto generado

El proyecto generado estÃ¡ organizado como un monorepo con dos aplicaciones principales:

### ğŸ“‚ apps/ â€“ Aplicaciones Principales

#### ğŸ¤– apps/agents/ â€“ Backend del Agente

Contiene toda la lÃ³gica del agente conversacional:

* `src/react-agent/`

  * `graph.ts`: â¤ï¸ NÃºcleo del agente â€“ Define el flujo de conversaciÃ³n y el grafo de estados
  * `configuration.ts`: âš™ï¸ ConfiguraciÃ³n del modelo y prompts
  * `tools.ts`: ğŸ› ï¸ Herramientas disponibles para el agente (como bÃºsqueda web)
  * `prompts.ts`: ğŸ’¬ Instrucciones base para el comportamiento del agente
  * `utils.ts`: ğŸ”§ Funciones auxiliares
* `tests/`

  * `integration/`: ğŸ”— Pruebas del flujo completo
  * `unit/`: ğŸ§ª Pruebas de componentes individuales

  ### Diagrama del grafo ReAct (Reason-Act)

```mermaid
flowchart TD
  Start["__start__"] --> CallModel["callModel"]
  CallModel -- "(flujo normal)" --> Tools["tools"]
  Tools --> CallModel
  CallModel -- "Sin tool calls\n(fin de conversaciÃ³n)" --> End["__end__"]
```

#### ğŸŒ apps/web/ â€“ Frontend de la AplicaciÃ³n

Interfaz en Next.js 15 para interactuar con el agente:

* `src/app/`: PÃ¡ginas, layouts y estilos globales
* `components/`

  * `thread/`: ğŸ§µ ConversaciÃ³n, historial, mensajes y herramientas
  * `agent-inbox/`: ğŸ“¥ Estado interno del agente y acciones
  * `ui/`: ğŸ›ï¸ Componentes de interfaz (botones, inputs, tarjetas)
* `hooks/`, `lib/`, `providers/`: ğŸ“¦ LÃ³gica compartida, streaming, estado y conexiÃ³n API

Esta estructura modular facilita la comprensiÃ³n del sistema, la personalizaciÃ³n del agente y su extensiÃ³n futura.

---

## ğŸ› ï¸ Paso 6 â€“ CreaciÃ³n de herramientas

En esta etapa aprenderÃ¡s cÃ³mo extender las capacidades de tu agente aÃ±adiendo herramientas personalizadas.

### ğŸ§  Wikipedia Tool

Usaremos la herramienta `WikipediaQueryRun` para que el agente pueda realizar bÃºsquedas en Wikipedia.

**InstalaciÃ³n:**

```bash
npm install @langchain/community
```

**Ejemplo de uso (en `apps/agents/src/react-agent/tools.ts`):**

```ts
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";

const wikipediaTool = new WikipediaQueryRun({
  topKResults: 3,
  maxDocContentLength: 4000,
});

// Actualiza el array TOOLS para incluir la nueva herramienta
export const TOOLS = [searchTavily, wikipediaTool];
```

Esto permitirÃ¡ al agente buscar y extraer informaciÃ³n de Wikipedia como parte de su razonamiento.

---

### ğŸ§© Tool personalizada â€“ adder

TambiÃ©n puedes crear herramientas propias usando la funciÃ³n `tool` de LangChain. Por ejemplo, una herramienta para sumar dos nÃºmeros:

**Ejemplo (en `tools.ts`):**

```ts
import { tool } from "@langchain/core/tools";
import { z } from "zod";

export const adderTool = tool(
  async ({ a, b }: { a: number; b: number }): Promise<string> => {
    const sum = a + b;
    return `La suma de ${a} y ${b} es ${sum}`;
  },
  {
    name: "adder",
    description: "Suma dos nÃºmeros proporcionados",
    schema: z.object({
      a: z.number(),
      b: z.number(),
    }),
  }
);
```

---

### ğŸŒ Tool personalizada â€“ consumo de API externa

Puedes integrar herramientas que se conecten a APIs externas. AquÃ­ un ejemplo que consume una API de clima:

```ts
import { tool } from "@langchain/core/tools";
import { z } from "zod";

export const weatherTool = tool(
  async ({ city }: { city: string }) => {
    const response = await fetch(`https://wttr.in/${city}?format=3`);
    const result = await response.text();
    return result;
  },
  {
    name: "weather",
    description: "Obtiene el clima actual de una ciudad",
    schema: z.object({
      city: z.string(),
    }),
  }
);
```

Esto permite que el agente haga consultas a APIs externas y use esa informaciÃ³n como parte de su respuesta.

### ğŸ§ª Reto: crea tu propia herramienta

Ahora que ya sabes cÃ³mo integrar herramientas externas y personalizadas, intenta crear una por tu cuenta.

Puedes inspirarte en las integraciones disponibles aquÃ­:
ğŸ‘‰ [Lista de herramientas en LangChain.js](https://js.langchain.com/docs/integrations/tools/)

**Ideas de herramientas personalizadas:**

* ğŸ“… Consulta de eventos en Google Calendar
* ğŸ“° BÃºsqueda de noticias con una API de noticias
* ğŸ“¦ Seguimiento de envÃ­os por nÃºmero de guÃ­a
* ğŸŒ¤ï¸ Clima actual en una ciudad
* ğŸ“ˆ Consulta de precios de criptomonedas o acciones

## Â¡AtrÃ©vete a experimentar!

---

* [DocumentaciÃ³n oficial de LangGraph](https://docs.langchain.com/langgraph)
* [GuÃ­a del generador create-agent-chat-app](https://github.com/langchain-ai/create-agent-chat-app)
* [Ejemplo de agente ReAct](https://github.com/langchain-ai/langgraph/blob/main/examples/react/README.md)

---


## ğŸ§® Paso 7 â€“ Ejercicio: Contador de llamadas a `callModel`

En este ejercicio aprenderÃ¡s a trabajar con el **estado** en LangGraph. ImplementarÃ¡s un contador que se incrementa cada vez que el nodo `callModel` es ejecutado.

### Â¿Por quÃ© es importante?
El estado permite que el agente recuerde informaciÃ³n entre pasos del grafo. Es fundamental para flujos conversacionales avanzados, seguimiento de contexto, historial, etc.

### Objetivo
Agregar una propiedad `callModelCount` al estado y hacer que se incremente automÃ¡ticamente en cada llamada a `callModel`.

### Pasos (compatible con la plantilla actual)

1. **Extiende el estado base de LangGraph**
   - Abre `apps/agents/src/react-agent/graph.ts`.
   - Extiende la anotaciÃ³n base para incluir el contador:

   ```ts
   import { MessagesAnnotation, Annotation } from "@langchain/langgraph";

   // Extiende el estado base para incluir el contador
   const CustomAnnotation = Annotation.Root({
     ...MessagesAnnotation.spec,
     callModelCount: Annotation<number>({
       value: (prev, next) => next,
       default: () => 0,
     }),
   });
   ```

2. **Usa el nuevo estado en el grafo**
   - Cambia la definiciÃ³n del grafo para usar tu anotaciÃ³n extendida:

   ```ts
   const workflow = new StateGraph(CustomAnnotation, ConfigurationSchema)
     // ...nodos y edges como antes...
   ```

3. **Incrementa el contador en `callModel`**
   - Ajusta la funciÃ³n para leer y actualizar el contador:

   ```ts
   async function callModel(
     state: typeof CustomAnnotation.State,
     config: RunnableConfig,
   ): Promise<typeof CustomAnnotation.Update> {
     // ...cÃ³digo existente...
     const currentCount = state.callModelCount ?? 0;
     // Llama al modelo como antes...
     const response = await model.invoke([
       // ...prompt...
       ...state.messages,
     ]);
     // Devuelve el nuevo estado, incrementando el contador
     return {
       messages: [response],
       callModelCount: currentCount + 1,
     };
   }
   ```

4. **Ajusta los tipos en el resto del archivo**
   - AsegÃºrate de que las funciones que reciben el estado usen `CustomAnnotation.State` en vez de `MessagesAnnotation.State`.

### Resultado esperado
Cada vez que el agente pase por el nodo `callModel`, el contador aumentarÃ¡. Puedes inspeccionar el estado en LangSmith Studio o imprimirlo para verificar que funciona.

### Diagrama del grafo condicional

```mermaid
flowchart TD
  Start["__start__"] --> CallModel["callModel"]
  CallModel -- "callModelCount < 3\n(sigue flujo normal)" --> Tools["tools"]
  Tools --> CallModel
  CallModel -- "callModelCount >= 3\n(lÃ­mite alcanzado)" --> MaxTurns["maxTurnsReached"]
  MaxTurns --> End["__end__"]
  CallModel -- "Sin tool calls\n(fin de conversaciÃ³n)" --> End
```

## ğŸ“š Ramas de ejercicios

Este repositorio contiene ramas especÃ­ficas para cada ejercicio prÃ¡ctico del taller:

- **`state-conditional`**: Incluye el ejercicio completo de agregar una variable de estado (`callModelCount`) y una arista condicional que cambia el flujo del grafo segÃºn ese estado.
- **`human`**: Muestra el cÃ³digo para implementar un flujo human-in-the-loop, donde el agente puede pausar la ejecuciÃ³n y pedir confirmaciÃ³n o input humano antes de continuar.

Puedes cambiar de rama con:

```bash
git switch state-conditional
# o
git switch human
```

Cada rama contiene el cÃ³digo y los comentarios necesarios para entender y probar el ejercicio correspondiente.

