# ğŸ§  Workshop â€“ Crea tu primer AI Agent con LangGraph

Este proyecto es una plantilla diseÃ±ada para enseÃ±ar a desarrolladores cÃ³mo crear agentes conversacionales usando LangGraph. Algunas de sus caracterÃ­sticas clave incluyen:

* Agente ReAct funcional, con razonamiento y herramientas
* Backend basado en LangGraph y LangChain
* Frontend moderno con Next.js 15, Tailwind CSS y Radix UI
* Arquitectura monorepo con Turborepo
* Streaming en tiempo real de respuestas del agente
* Soporte para mÃºltiples modelos LLM como Anthropic Claude y OpenAI GPT
* IntegraciÃ³n con herramientas externas como Tavily
* Interfaz de chat interactiva y personalizable

Este proyecto sirve como base para aprender, prototipar y extender agentes mÃ¡s avanzados.

Este repositorio contiene los pasos y materiales necesarios para completar el workshop de creaciÃ³n de agentes conversacionales con [LangGraph](https://github.com/langchain-ai/langgraph).

AprenderÃ¡s a generar un proyecto desde cero usando [`create-agent-chat-app`](https://github.com/langchain-ai/create-agent-chat-app) y a personalizar un agente ReAct dentro de una app React con Next.js.

---

## ğŸš€ Paso 1 â€“ Genera tu proyecto

Ejecuta el siguiente comando en tu terminal:

```bash
npx create-agent-chat-app
```

Responde a las siguientes opciones cuando se te pregunte:

```
â—‡  What is the name of your project? my-first-agent
â—‡  Which package manager would you like to use? â€º npm
â—‡  Would you like to automatically install dependencies? Y
â—‡  Which framework would you like to use? â€º Next.js
â—†  Which pre-built agents would you like to include?
â”‚  [x] ReAct Agent
â”‚  [ ] Memory Agent
â”‚  [ ] Research Agent
â”‚  [ ] Retrieval Agent
```

Esto crearÃ¡ una nueva carpeta `my-first-agent` con todo el cÃ³digo necesario para empezar.

---

## âš™ï¸ Paso 2 â€“ Configura las variables de entorno

Dentro del directorio del proyecto (`my-first-agent`), copia el archivo de ejemplo de variables de entorno:

```bash
cp .env.example .env
```

> ğŸ“ Este archivo contiene las claves necesarias para ejecutar el agente. AsegÃºrate de reemplazar los valores por tus propias credenciales antes de continuar.

NecesitarÃ¡s obtener claves API desde los siguientes proveedores:

* [Anthropic](https://console.anthropic.com/account/keys)
* [OpenAI](https://platform.openai.com/api-keys)
* [Tavily](https://app.tavily.com/settings/api-keys)
* Gemini, Grok, etc.

> âš™ï¸ El proyecto viene configurado por defecto para funcionar con **Anthropic**. Si deseas usar otro proveedor (como OpenAI), ademÃ¡s de configurar la clave correspondiente en el `.env`, debes modificar el modelo por defecto en el archivo:
>
> ```ts
> apps/agents/src/react-agent/configuration.ts
> ```

---

## ğŸ’» Paso 3 â€“ Ejecuta el proyecto en desarrollo

Dentro del directorio del proyecto:

```bash
npm run dev
```

Luego abre tu navegador en:

```
http://localhost:3000
```

AhÃ­ podrÃ¡s empezar a interactuar con tu primer agente conversacional.

AdemÃ¡s, si estÃ¡s ejecutando el backend correctamente, tambiÃ©n tendrÃ¡s acceso a:

* ğŸš€ API: [http://localhost:2024](http://localhost:2024)
* ğŸ¨ Studio UI: [https://smith.langchain.com/studio?baseUrl=http://localhost:2024](https://smith.langchain.com/studio?baseUrl=http://localhost:2024) â€“ esta herramienta permite interactuar y depurar el comportamiento del agente en tiempo real

---

## ğŸ“ Paso 4 â€“ Â¿Y ahora quÃ©?

En esta etapa vamos a interactuar directamente con el agente.

Puedes hacer lo siguiente:

* Utiliza la ventana de chat en `http://localhost:3000` para probar prompts y ver cÃ³mo responde el agente.
* Abre la interfaz de LangSmith Studio ([https://smith.langchain.com/studio?baseUrl=http://localhost:2024](https://smith.langchain.com/studio?baseUrl=http://localhost:2024)) para observar cÃ³mo se ejecutan los pasos del grafo en tiempo real, ver trazas y depurar su comportamiento.

---

## ğŸ§© Paso 5 â€“ DescripciÃ³n del proyecto generado

El proyecto generado estÃ¡ organizado como un monorepo con dos aplicaciones principales:

### ğŸ“‚ apps/ â€“ Aplicaciones Principales

#### ğŸ¤– apps/agents/ â€“ Backend del Agente

Contiene toda la lÃ³gica del agente conversacional:

* `src/react-agent/`

  * `graph.ts`: â¤ï¸ NÃºcleo del agente â€“ Define el flujo de conversaciÃ³n y el grafo de estados
  * `configuration.ts`: âš™ï¸ ConfiguraciÃ³n del modelo y prompts
  * `tools.ts`: ğŸ› ï¸ Herramientas disponibles para el agente (como bÃºsqueda web)
  * `prompts.ts`: ğŸ’¬ Instrucciones base para el comportamiento del agente
  * `utils.ts`: ğŸ”§ Funciones auxiliares
* `tests/`

  * `integration/`: ğŸ”— Pruebas del flujo completo
  * `unit/`: ğŸ§ª Pruebas de componentes individuales

#### ğŸŒ apps/web/ â€“ Frontend de la AplicaciÃ³n

Interfaz en Next.js 15 para interactuar con el agente:

* `src/app/`: PÃ¡ginas, layouts y estilos globales
* `components/`

  * `thread/`: ğŸ§µ ConversaciÃ³n, historial, mensajes y herramientas
  * `agent-inbox/`: ğŸ“¥ Estado interno del agente y acciones
  * `ui/`: ğŸ›ï¸ Componentes de interfaz (botones, inputs, tarjetas)
* `hooks/`, `lib/`, `providers/`: ğŸ“¦ LÃ³gica compartida, streaming, estado y conexiÃ³n API

Esta estructura modular facilita la comprensiÃ³n del sistema, la personalizaciÃ³n del agente y su extensiÃ³n futura.

---

## ğŸ› ï¸ Paso 6 â€“ CreaciÃ³n de herramientas

En esta etapa aprenderÃ¡s cÃ³mo extender las capacidades de tu agente aÃ±adiendo herramientas personalizadas.

### ğŸ§  Wikipedia Tool

Usaremos la herramienta `WikipediaQueryRun` para que el agente pueda realizar bÃºsquedas en Wikipedia.

**InstalaciÃ³n:**

```bash
npm install @langchain/community
```

**Ejemplo de uso (en `apps/agents/src/react-agent/tools.ts`):**

```ts
import { WikipediaQueryRun } from "@langchain/community/tools/wikipedia_query_run";

export const wikipediaTool = new WikipediaQueryRun({
  topKResults: 3,
  maxDocContentLength: 4000,
});

export const TOOLS = [searchTavily, wikipediaTool];
```

Esto permitirÃ¡ al agente buscar y extraer informaciÃ³n de Wikipedia como parte de su razonamiento.

---

### ğŸ§© Tool personalizada â€“ adder

TambiÃ©n puedes crear herramientas propias usando la funciÃ³n `tool` de LangChain. Por ejemplo, una herramienta para sumar dos nÃºmeros:

**Ejemplo (en `tools.ts`):**

```ts
import { tool } from "@langchain/core/tools";
import { z } from "zod";

export const adderTool = tool(
  async ({ a, b }: { a: number; b: number }): Promise<string> => {
    const sum = a + b;
    return `La suma de ${a} y ${b} es ${sum}`;
  },
  {
    name: "adder",
    description: "Suma dos nÃºmeros proporcionados",
    schema: z.object({
      a: z.number(),
      b: z.number(),
    }),
  }
);
```

---

### ğŸŒ Tool personalizada â€“ consumo de API externa

Puedes integrar herramientas que se conecten a APIs externas. AquÃ­ un ejemplo que consume una API de clima:

```ts
import { tool } from "@langchain/core/tools";
import { z } from "zod";

export const weatherTool = tool(
  async ({ city }: { city: string }) => {
    const response = await fetch(`https://wttr.in/${city}?format=3`);
    const result = await response.text();
    return result;
  },
  {
    name: "weather",
    description: "Obtiene el clima actual de una ciudad",
    schema: z.object({
      city: z.string(),
    }),
  }
);
```

Esto permite que el agente haga consultas a APIs externas y use esa informaciÃ³n como parte de su respuesta.

### ğŸ§ª Reto: crea tu propia herramienta

Ahora que ya sabes cÃ³mo integrar herramientas externas y personalizadas, intenta crear una por tu cuenta.

Puedes inspirarte en las integraciones disponibles aquÃ­:
ğŸ‘‰ [Lista de herramientas en LangChain.js](https://js.langchain.com/docs/integrations/tools/)

**Ideas de herramientas personalizadas:**

* ğŸ“… Consulta de eventos en Google Calendar
* ğŸ“° BÃºsqueda de noticias con una API de noticias
* ğŸ“¦ Seguimiento de envÃ­os por nÃºmero de guÃ­a
* ğŸŒ¤ï¸ Clima actual en una ciudad
* ğŸ“ˆ Consulta de precios de criptomonedas o acciones

## Â¡AtrÃ©vete a experimentar!

## ğŸ§â€â™‚ï¸ Paso 7 â€“ Human in the Loop (ImplementaciÃ³n Avanzada)

LangGraph permite incluir intervenciÃ³n humana durante la ejecuciÃ³n del agente. Este proyecto implementa dos tipos de interrupciones personalizadas que van mÃ¡s allÃ¡ del simple `interruptBefore`.

### ğŸ¯ ImplementaciÃ³n Actual

El proyecto incluye **dos tipos de interrupciones** implementadas como nodos personalizados:

#### 1. **GenericInterrupt** (Vista de Solo Lectura)
- Muestra informaciÃ³n detallada sobre las herramientas que se ejecutarÃ¡n
- Interfaz de tabla expandible
- Solo visualizaciÃ³n, sin botones de acciÃ³n

#### 2. **Agent Inbox** (Interfaz Interactiva)
- Botones de Aprobar/Rechazar
- Campos editables
- Soporte para respuestas personalizadas
- UI completamente funcional

### ğŸ› ï¸ ImplementaciÃ³n TÃ©cnica

**Paso 1: Importaciones necesarias**

En `apps/agents/src/react-agent/graph.ts`:

```ts
import { interrupt } from "@langchain/langgraph";
import { HumanInterrupt } from "@langchain/langgraph/prebuilt";
```

**Paso 2: Nodo para GenericInterrupt**

```ts
async function humanApproval(
  state: typeof MessagesAnnotation.State,
  config: RunnableConfig,
): Promise<typeof MessagesAnnotation.Update> {
  const messages = state.messages;
  const lastMessage = messages[messages.length - 1] as AIMessage;
  
  const toolCalls = lastMessage.tool_calls || [];
  
  const interruptData = {
    message: "Se van a ejecutar las siguientes herramientas. Â¿Desea continuar?",
    toolCalls: toolCalls.map(tc => ({
      name: tc.name,
      id: tc.id,
      arguments: tc.args
    })),
    totalTools: toolCalls.length,
    timestamp: new Date().toISOString()
  };
  
  interrupt(interruptData);
  return { messages: [] };
}
```

**Paso 3: Nodo para Agent Inbox**

```ts
async function humanApprovalWithActions(
  state: typeof MessagesAnnotation.State,
  config: RunnableConfig,
): Promise<typeof MessagesAnnotation.Update> {
  const messages = state.messages;
  const lastMessage = messages[messages.length - 1] as AIMessage;
  
  const toolCalls = lastMessage.tool_calls || [];
  const toolCallsDescription = toolCalls.map(tc => 
    `${tc.name}(${JSON.stringify(tc.args)})`
  ).join(", ");
  
  const humanInterruptData: HumanInterrupt = {
    action_request: {
      action: "approve_tool_execution",
      args: {
        toolCalls: toolCalls,
        totalTools: toolCalls.length,
        proposedActions: toolCallsDescription
      }
    },
    description: `El agente quiere ejecutar las siguientes herramientas: ${toolCallsDescription}. Â¿Desea aprobar la ejecuciÃ³n?`,
    config: {
      allow_edit: false,
      allow_respond: false,
      allow_ignore: true,
      allow_accept: true
    }
  };
  
  interrupt(humanInterruptData);
  return { messages: [] };
}
```

**Paso 4: ConfiguraciÃ³n del Grafo**

```ts
// FunciÃ³n de enrutamiento
function routeModelOutput(state: typeof MessagesAnnotation.State): string {
  const messages = state.messages;
  const lastMessage = messages[messages.length - 1];
  
  if ((lastMessage as AIMessage)?.tool_calls?.length || 0 > 0) {
    return "humanApprovalWithActions"; // o "humanApproval"
  }
  return "__end__";
}

// ConfiguraciÃ³n del workflow
const workflow = new StateGraph(MessagesAnnotation, ConfigurationSchema)
  .addNode("callModel", callModel)
  .addNode("humanApproval", humanApproval)
  .addNode("humanApprovalWithActions", humanApprovalWithActions)
  .addNode("tools", new ToolNode(TOOLS))
  .addEdge("__start__", "callModel")
  .addConditionalEdges("callModel", routeModelOutput)
  .addEdge("humanApproval", "tools")
  .addEdge("humanApprovalWithActions", "tools")
  .addEdge("tools", "callModel");

// CompilaciÃ³n sin interruptBefore/interruptAfter
export const graph = workflow.compile({
  interruptBefore: [],
  interruptAfter: [],
});
```

**Paso 5: Cambiar entre tipos de interrupciÃ³n**

Para alternar entre los dos tipos, simplemente cambia el valor de retorno en `routeModelOutput`:

```ts
// Para GenericInterrupt (solo lectura)
return "humanApproval";

// Para Agent Inbox (con botones)
return "humanApprovalWithActions";
```

### ğŸ“Š Comparativa de Implementaciones

| CaracterÃ­stica | GenericInterrupt | Agent Inbox | interruptBefore |
|---------------|------------------|-------------|-----------------|
| **UI** | Tabla expandible | Botones interactivos | GenericInterrupt por defecto |
| **Datos** | Objeto personalizado | Esquema HumanInterrupt | undefined |
| **InteracciÃ³n** | Solo lectura | Aprobar/Rechazar/Editar | Solo lectura |
| **Complejidad** | ğŸŸ¡ Media | ğŸŸ¢ Baja | ğŸŸ¢ Muy Baja |
| **Control** | ğŸŸ¡ Media | ğŸŸ¢ Alta | ğŸ”´ Limitado |

### âš™ï¸ Diferencias Clave con interruptBefore

**âŒ Problema con interruptBefore:**
```ts
// Esto solo pausa, pero threadInterrupt.value es undefined
export const graph = workflow.compile({
  interruptBefore: ["tools"]
});
```

**âœ… SoluciÃ³n con nodos personalizados:**
- Proporcionan datos estructurados a la UI
- Control total sobre el contenido mostrado
- Diferentes tipos de interacciones segÃºn el esquema usado

### ğŸš€ Resultado

Con esta implementaciÃ³n obtienes:

1. **Control granular** sobre cuÃ¡ndo y cÃ³mo interrumpir
2. **Datos ricos** para mostrar en la interfaz
3. **Flexibilidad** para diferentes tipos de interrupciones
4. **UI nativa** que se integra perfectamente con el sistema

### ğŸ”§ PrÃ³ximos Pasos

- Experimenta cambiando entre `humanApproval` y `humanApprovalWithActions`
- Personaliza los datos mostrados en `interruptData`
- Modifica las opciones en `config` para controlar quÃ© botones mostrar
- Agrega validaciones personalizadas antes de ejecutar herramientas

---

* [DocumentaciÃ³n oficial de LangGraph](https://docs.langchain.com/langgraph)
* [GuÃ­a del generador create-agent-chat-app](https://github.com/langchain-ai/create-agent-chat-app)
* [Ejemplo de agente ReAct](https://github.com/langchain-ai/langgraph/blob/main/examples/react/README.md)

---

## âœ¨ CrÃ©dito

Este workshop fue preparado por \[Tu Nombre] para ayudar a desarrolladores a dar sus primeros pasos construyendo agentes conversacionales con LangGraph.
